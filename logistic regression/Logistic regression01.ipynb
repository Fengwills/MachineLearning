{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <center>Supervised Learning</center>\n",
    "\n",
    "- making inferences from labeled data.\n",
    "\n",
    "#### 1. Classification (categorical data)\n",
    "- binary classification (tumor: benign, malignant)\n",
    "- multiclass classification (books: maths, physics, stats, psychology, etc.)\n",
    "- example algorithms: KNN, Linear Models, Decision Trees, SVMs, etc.\n",
    "\n",
    "#### 2. Regression (continuous data)\n",
    "- predicting income, price of stock, age, and other continous data \n",
    "- example algorithms: KNN, Linear Regression, Decision Trees, SVMs, etc.\n",
    "___\n",
    "\n",
    "Linear models (Linear Regression, Polynormal Regression, Gaussian Regression, Sigmoid Regression, etc) - make predictions according to a linear function of the input features. <br>\n",
    "Many ML algorithms (including those specified above) can be used for both classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is the special case of linear regression where dependent or output variable is categorical. Logistic in logistic regression comes from the function which is the core of this algorithm. This function is logistic function or sigmoid function . Logistic function can be written as : \n",
    "\n",
    "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "![Sigmoid function](images/sigmoid.png)\n",
    "\n",
    "Logistic regression is the classification algorithm.  We can implement this function in numpy as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "#mpl.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.        , -19.18367347, -18.36734694, -17.55102041,\n",
       "       -16.73469388, -15.91836735, -15.10204082, -14.28571429,\n",
       "       -13.46938776, -12.65306122, -11.83673469, -11.02040816,\n",
       "       -10.20408163,  -9.3877551 ,  -8.57142857,  -7.75510204,\n",
       "        -6.93877551,  -6.12244898,  -5.30612245,  -4.48979592,\n",
       "        -3.67346939,  -2.85714286,  -2.04081633,  -1.2244898 ,\n",
       "        -0.40816327,   0.40816327,   1.2244898 ,   2.04081633,\n",
       "         2.85714286,   3.67346939,   4.48979592,   5.30612245,\n",
       "         6.12244898,   6.93877551,   7.75510204,   8.57142857,\n",
       "         9.3877551 ,  10.20408163,  11.02040816,  11.83673469,\n",
       "        12.65306122,  13.46938776,  14.28571429,  15.10204082,\n",
       "        15.91836735,  16.73469388,  17.55102041,  18.36734694,\n",
       "        19.18367347,  20.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = np.linspace(-20,20,50) #generate a list of numbers\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06115362e-09, 4.66268920e-09, 1.05478167e-08, 2.38610019e-08,\n",
       "       5.39777490e-08, 1.22107080e-07, 2.76227484e-07, 6.24874560e-07,\n",
       "       1.41357420e-06, 3.19774584e-06, 7.23382998e-06, 1.63640365e-05,\n",
       "       3.70175420e-05, 8.37362281e-05, 1.89405944e-04, 4.28366894e-04,\n",
       "       9.68517025e-04, 2.18827951e-03, 4.93663522e-03, 1.10983776e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will pass each number through sigmoid function\n",
    "results = sigmoid(numbers)\n",
    "results[:20]  #print few numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all numbers are squashed between [0,1]\n",
    "Now, we will implement logistic regression using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using LogisticRegression on the cancer dataset. \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 0.953\n",
      "Accuracy on the test subset: 0.958\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the training subset: {:.3f}'.format(log_reg.score(X_train, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(log_reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Regularization**:\n",
    "\n",
    "- prevention of overfitting - (according to Muller and Guido ML book)\n",
    "- L1 - assumes only a few features are important\n",
    "- L2 - does not assume only a few features are important - used by default in scikit-learn LogisticRegression\n",
    "               \n",
    "**'C'**:\n",
    "\n",
    "- parameter to control the strength of regularization\n",
    "- lower C => logistic regression adjusts to the majority of data points.\n",
    "- higher C => correct classification of each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 0.972\n",
      "Accuracy on the test subset: 0.965\n"
     ]
    }
   ],
   "source": [
    "log_reg100 = LogisticRegression(C=100)\n",
    "log_reg100.fit(X_train, y_train)\n",
    "print('Accuracy on the training subset: {:.3f}'.format(log_reg100.score(X_train, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(log_reg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 0.934\n",
      "Accuracy on the test subset: 0.930\n"
     ]
    }
   ],
   "source": [
    "log_reg001 = LogisticRegression(C=0.01)\n",
    "log_reg001.fit(X_train, y_train)\n",
    "print('Accuracy on the training subset: {:.3f}'.format(log_reg001.score(X_train, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(log_reg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
