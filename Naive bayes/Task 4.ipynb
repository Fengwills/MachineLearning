{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Implementing Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Spambase  \n",
    "Implement Gaussian naïve bayes by yourself, instead of calling function GaussianNB  \n",
    "Using 10-fold cross validation for evaluation  \n",
    "Evaluation matrices: Accuracy, Precision, Recall, F1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbols\n",
    "\n",
    "Given training set $T$\n",
    "\n",
    "$$T = \\{(x_1, y_1), (x_2, y_2), ···, (x_N, y_N)\\}$$\n",
    "\n",
    "where $x_i$ is feature for $i$-th sample，$y_i$ is the lable for $i$-th sample , $y_i \\in \\{ c_1, c_2, ..., c_k\\}$。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian rule\n",
    "\n",
    "Bayesian rule：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    P(Y = c_k \\mid X = x) &= \\frac{P(Y = c_k, X = x)}{P(X = x)} \\\\\n",
    "                  &= \\frac{P(X = x \\mid Y = c_k)P(Y = c_k)}{\\sum_kP(X = x \\mid Y = c_k)P(Y = c_k)} \\\\\n",
    "                  & \\propto P(X = x \\mid Y = c_k)P(Y = c_k) \\\\\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prior distribution\n",
    "\n",
    "$$\n",
    "P(Y = c_k), \\ k = 1, 2, ..., K\n",
    "$$\n",
    "\n",
    "conditonal distribution \n",
    "\n",
    "$$\n",
    "P(X = x \\mid Y = c_k) = P(X^{(1)} = x^{(1)}, ···, X^{(n)} = x^{(n)} \\mid Y = c_k), \\ k = 1, 2, ..., K\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to obtain prior and likelihood？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prior $P(Y = c_k)$ ：\n",
    "\n",
    "\n",
    "$$\n",
    "P(Y = c_k) = \\frac{\\mathrm{number} \\ \\mathrm{of}\\ c_k}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. likilihood $P(X = x \\mid Y = c_k)$ ：\n",
    "\n",
    "\n",
    "$$P(X = x \\mid Y = c_k) = \\prod^n_{j=1}P(X^{(j)}=x^{(j)} \\mid Y = c_k)$$\n",
    "\n",
    "where $x^{(j)}$ is the $j$-th feature of sample $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conditional distribution for feature $j$  $P(X^{(j)}=x^{(j)} \\mid Y = c_k)$ ：\n",
    "\n",
    "$$\n",
    "P(X^{(j)} = a_{jl} \\mid Y = c_k) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2_{c_k,j}}} \\exp{\\bigg( - \\frac{(a_{jl} - \\mu_{c_k,j})^2}{2 \\sigma^2_{c_k,j}} \\bigg)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ojvective function\n",
    "\n",
    "we can obtain the objective function of Gaussian naive bayes：\n",
    "\n",
    "$$\n",
    "y = \\mathop{\\arg\\max}_{c_k} P(Y = c_k) \\prod_j P(X^{(j)} = x^{(j)} \\mid Y = c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Usually, the log of the conditional distribution is used for convenience\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y &= \\mathop{\\arg\\max}_{c_k} \\big[ \\log^{ \\ P(Y = c_k) \\prod_j P(X^{(j)} = x^{(j)} \\mid Y = c_k)} \\big] \\\\\n",
    "&= \\mathop{\\arg\\max}_{c_k} \\big[ \\log^{ \\ P(y = c_k)} + \\sum_j \\log^{ \\ P(X^{(j)} = x^{(j)} \\mid Y = c_k)} \\big]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\log^{ \\ P(X^{(j)} = x^{(j)} \\mid Y = c_k)} &= \\log^{ \\ \\bigg[\\frac{1}{\\sqrt{2 \\pi \\sigma^2_{c_k,j}}} \\exp{\\bigg(- \\frac{(a_{jl} - \\mu_{c_k,j})^2}{2 \\sigma^2_{c_k,j}}\\bigg)}\\bigg]}\\\\\n",
    "&= \\log^{ \\frac{1}{\\sqrt{2 \\pi \\sigma^2_{c_k,j}}} } + \\log^{ \\exp{\\bigg(- \\frac{(a_{jl} - \\mu_{c_k,j})^2}{2 \\sigma^2_{c_k,j}}\\bigg)} }\\\\\n",
    "&= - \\frac{1}{2} \\log^{2 \\pi \\sigma^2_{c_k,j}} - \\frac{1}{2} \\frac{(a_{jl} - \\mu_{c_k,j})^2}{\\sigma^2_{c_k,j}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "y = \\mathop{\\arg\\max}_{c_k} \\bigg[ \\log^{ \\ P(y = c_k)} + \\sum_j \\big( - \\frac{1}{2} \\log^{2 \\pi \\sigma^2_{c_k,j}} - \\frac{1}{2} \\frac{(a_{jl} - \\mu_{c_k,j})^2}{\\sigma^2_{c_k,j}} \\big) \\bigg]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inport dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spambase = np.loadtxt('data/spambase/spambase.data', delimiter = \",\")\n",
    "spamx = spambase[:, :57]\n",
    "spamy = spambase[:, 57]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(spamx, spamy, test_size = 0.4, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implement Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = myGaussianNB()\n",
    "model.fit(trainX, trainY)\n",
    "accuracy_score(testY, model.predict(testX))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Results in different metrics\n",
    "\n",
    "###### Input your results\n",
    "\n",
    "Precision|Accuracy|Recall|F1\n",
    "-|-|-|-\n",
    "0.0|0.0|0.0|0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
